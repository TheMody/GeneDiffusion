@ARTICLE{10.3389/fsysb.2022.877717,
AUTHOR={Shen, Xiaoxi and Jiang, Chang and Wen, Yalu and Li, Chenxi and Lu, Qing},   
TITLE={A Brief Review on Deep Learning Applications in Genomic Studies},      
JOURNAL={Frontiers in Systems Biology},      
VOLUME={2},           
YEAR={2022},        
URL={https://www.frontiersin.org/articles/10.3389/fsysb.2022.877717},       
DOI={10.3389/fsysb.2022.877717},      
ISSN={2674-0702},    
ABSTRACT={Deep learning is a powerful tool for capturing complex structures within the data. It holds great promise for genomic research due to its capacity of learning complex features in genomic data. In this paper, we provide a brief review on deep learning techniques and various applications of deep learning to genomic studies. We also briefly mention current challenges and future perspectives on using emerging deep learning techniques for ongoing and future genomic research.}
}

@inproceedings{beyer1999nearest,
  title={When is “nearest neighbor” meaningful?},
  author={Beyer, Kevin and Goldstein, Jonathan and Ramakrishnan, Raghu and Shaft, Uri},
  booktitle={International conference on database theory},
  pages={217--235},
  year={1999},
  organization={Springer}
}

@ARTICLE{Guo2023-pj,
  title    = "Diffusion models in bioinformatics and computational biology",
  author   = "Guo, Zhiye and Liu, Jian and Wang, Yanli and Chen, Mengrui and
              Wang, Duolin and Xu, Dong and Cheng, Jianlin",
  abstract = "Denoising diffusion models embody a type of generative artificial
              intelligence that can be applied in computer vision, natural
              language processing and bioinformatics. In this Review, we
              introduce the key concepts and theoretical foundations of three
              diffusion modelling frameworks (denoising diffusion probabilistic
              models, noise-conditioned scoring networks and score stochastic
              differential equations). We then explore their applications in
              bioinformatics and computational biology, including protein
              design and generation, drug and small-molecule design,
              protein-ligand interaction modelling, cryo-electron microscopy
              image data analysis and single-cell data analysis. Finally, we
              highlight open-source diffusion model tools and consider the
              future applications of diffusion models in bioinformatics.",
  journal  = "Nat Rev Bioeng",
  volume   =  2,
  number   =  2,
  pages    = "136--154",
  month    =  oct,
  year     =  2023,
  address  = "England",
  language = "en"
}
@inproceedings{fredrikson2014privacy,
  title={Privacy in pharmacogenetics: An $\{$End-to-End$\}$ case study of personalized warfarin dosing},
  author={Fredrikson, Matthew and Lantz, Eric and Jha, Somesh and Lin, Simon and Page, David and Ristenpart, Thomas},
  booktitle={23rd USENIX security symposium (USENIX Security 14)},
  pages={17--32},
  year={2014}
}

@article{dockhorn2022differentially,
  title={Differentially private diffusion models},
  author={Dockhorn, Tim and Cao, Tianshi and Vahdat, Arash and Kreis, Karsten},
  journal={arXiv preprint arXiv:2210.09929},
  year={2022}
}

@Article{Uffelmann2021,
author={Uffelmann, Emil
and Huang, Qin Qin
and Munung, Nchangwi Syntia
and de Vries, Jantina
and Okada, Yukinori
and Martin, Alicia R.
and Martin, Hilary C.
and Lappalainen, Tuuli
and Posthuma, Danielle},
title={Genome-wide association studies},
journal={Nature Reviews Methods Primers},
year={2021},
month={Aug},
day={26},
volume={1},
number={1},
pages={59},
abstract={Genome-wide association studies (GWAS) test hundreds of thousands of genetic variants across many genomes to find those statistically associated with a specific trait or disease. This methodology has generated a myriad of robust associations for a range of traits and diseases, and the number of associated variants is expected to grow steadily as GWAS sample sizes increase. GWAS results have a range of applications, such as gaining insight into a phenotype's underlying biology, estimating its heritability, calculating genetic correlations, making clinical risk predictions, informing drug development programmes and inferring potential causal relationships between risk factors and health outcomes. In this Primer, we provide the reader with an introduction to GWAS, explaining their statistical basis and how they are conducted, describe state-of-the art approaches and discuss limitations and challenges, concluding with an overview of the current and future applications for GWAS results.},
issn={2662-8449},
doi={10.1038/s43586-021-00056-9},
url={https://doi.org/10.1038/s43586-021-00056-9}
}

@inproceedings{sohl2015deep,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={International conference on machine learning},
  pages={2256--2265},
  year={2015},
  organization={PMLR}
}

@InProceedings{Unet,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}

@article{cheng2023accurate,
  title={Accurate proteome-wide missense variant effect prediction with AlphaMissense},
  author={Cheng, Jun and Novati, Guido and Pan, Joshua and Bycroft, Clare and {\v{Z}}emgulyt{\.e}, Akvil{\.e} and Applebaum, Taylor and Pritzel, Alexander and Wong, Lai Hong and Zielinski, Michal and Sargeant, Tobias and others},
  journal={Science},
  volume={381},
  number={6664},
  pages={eadg7492},
  year={2023},
  publisher={American Association for the Advancement of Science}
}

@article{wong2024discovery,
  title={Discovery of a structural class of antibiotics with explainable deep learning},
  author={Wong, Felix and Zheng, Erica J and Valeri, Jacqueline A and Donghia, Nina M and Anahtar, Melis N and Omori, Satotaka and Li, Alicia and Cubillos-Ruiz, Andres and Krishnan, Aarti and Jin, Wengong and others},
  journal={Nature},
  volume={626},
  number={7997},
  pages={177--185},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{schwarze2018whole,
  title={Are whole-exome and whole-genome sequencing approaches cost-effective? A systematic review of the literature},
  author={Schwarze, Katharina and Buchanan, James and Taylor, Jenny C and Wordsworth, Sarah},
  journal={Genetics in Medicine},
  volume={20},
  number={10},
  pages={1122--1130},
  year={2018},
  publisher={Elsevier}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{zhang2019identity,
  title={Identity crisis: Memorization and generalization under extreme overparameterization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Mozer, Michael C and Singer, Yoram},
  journal={arXiv preprint arXiv:1902.04698},
  year={2019}
}

@inproceedings{duan2023diffusion,
  title={Are diffusion models vulnerable to membership inference attacks?},
  author={Duan, Jinhao and Kong, Fei and Wang, Shiqi and Shi, Xiaoshuang and Xu, Kaidi},
  booktitle={International Conference on Machine Learning},
  pages={8717--8730},
  year={2023},
  organization={PMLR}
}

@inproceedings{yale2019privacy,
  title={Privacy preserving synthetic health data},
  author={Yale, Andrew and Dash, Saloni and Dutta, Ritik and Guyon, Isabelle and Pavao, Adrien and Bennett, Kristin P},
  booktitle={ESANN 2019-European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning},
  year={2019}
}

@article{yelmen2021creating,
  title={Creating artificial human genomes using generative neural networks},
  author={Yelmen, Burak and Decelle, Aur{\'e}lien and Ongaro, Linda and Marnetto, Davide and Tallec, Corentin and Montinaro, Francesco and Furtlehner, Cyril and Pagani, Luca and Jay, Flora},
  journal={PLoS genetics},
  volume={17},
  number={2},
  pages={e1009303},
  year={2021},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{alphafold,
  title={Highly accurate protein structure prediction with AlphaFold},
  author={Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko, Anna and others},
  journal={Nature},
  volume={596},
  number={7873},
  pages={583--589},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{
azizi2023synthetic,
title={Synthetic Data from Diffusion Models Improves ImageNet Classification},
author={Shekoofeh Azizi and Simon Kornblith and Chitwan Saharia and Mohammad Norouzi and David J. Fleet},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
url={https://openreview.net/forum?id=DlRsoxjyPm},
note={}
}

@inproceedings{
dosovitskiy2021an,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=YicbFdNTTy}
}

@misc{nguyen2023hyenadna,
      title={HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution}, 
      author={Eric Nguyen and Michael Poli and Marjan Faizi and Armin Thomas and Callum Birch-Sykes and Michael Wornow and Aman Patel and Clayton Rabideau and Stefano Massaroli and Yoshua Bengio and Stefano Ermon and Stephen A. Baccus and Chris Ré},
      year={2023},
      eprint={2306.15794},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{ddpm,
      author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
        title={Denoising Diffusion Probabilistic Models}, 
      year={2020},
      eprint={2006.11239},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ddim,
      title={Denoising Diffusion Implicit Models}, 
      author={Jiaming Song and Chenlin Meng and Stefano Ermon},
      year={2022},
      eprint={2010.02502},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{schiff2024caduceusbidirectionalequivariantlongrange,
      title={Caduceus: Bi-Directional Equivariant Long-Range DNA Sequence Modeling}, 
      author={Yair Schiff and Chia-Hsiang Kao and Aaron Gokaslan and Tri Dao and Albert Gu and Volodymyr Kuleshov},
      year={2024},
      eprint={2403.03234},
      archivePrefix={arXiv},
      primaryClass={q-bio.GN},
      url={https://arxiv.org/abs/2403.03234}, 
}

@article{is,
  title={Improved techniques for training gans},
  author={Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{fid,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{dolzhenko2017detection,
  title={Detection of long repeat expansions from PCR-free whole-genome sequence data},
  author={Dolzhenko, Egor and Van Vugt, Joke Jfa and Shaw, Richard J and Bekritsky, Mitchell A and Van Blitterswijk, Marka and Narzisi, Giuseppe and Ajay, Subramanian S and Rajan, Vani and Lajoie, Bryan R and Johnson, Nathan H and others},
  journal={Genome research},
  volume={27},
  number={11},
  pages={1895--1903},
  year={2017},
  publisher={Cold Spring Harbor Lab}
}

@article{auer2012imputation,
  title={Imputation of exome sequence variants into population-based samples and blood-cell-trait-associated loci in African Americans: NHLBI GO Exome Sequencing Project},
  author={Auer, Paul L and Johnsen, Jill M and Johnson, Andrew D and Logsdon, Benjamin A and Lange, Leslie A and Nalls, Michael A and Zhang, Guosheng and Franceschini, Nora and Fox, Keolu and Lange, Ethan M and others},
  journal={The American Journal of Human Genetics},
  volume={91},
  number={5},
  pages={794--808},
  year={2012},
  publisher={Elsevier}
}

@article{zhang2023dnagpt,
  title={DNAGPT: a generalized pretrained tool for multiple DNA sequence analysis tasks},
  author={Zhang, Daoan and Zhang, Weitong and He, Bing and Zhang, Jianguo and Qin, Chenchen and Yao, Jianhua},
  journal={bioRxiv},
  pages={2023--07},
  year={2023},
  publisher={Cold Spring Harbor Laboratory}
}

@inproceedings{perera2022generative,
  title={Generative moment matching networks for genotype simulation},
  author={Perera, Maria and Montserrat, Daniel Mas and Barrab{\'e}s, M{\'\i}riam and Geleta, Margarita and Gir{\'o}-i-Nieto, Xavier and Ioannidis, Alexander G},
  booktitle={2022 44th Annual International Conference of the IEEE Engineering in Medicine \& Biology Society (EMBC)},
  pages={1379--1383},
  year={2022},
  organization={IEEE}
}
@article{dang2023tractable,
  title={Tractable and expressive generative models of genetic variation data},
  author={Dang, Meihua and Liu, Anji and Wei, Xinzhu and Sankararaman, Sriram and Van den Broeck, Guy},
  journal={bioRxiv},
  year={2023},
  publisher={Cold Spring Harbor Laboratory Preprints}
}

@article{burnard2023generating,
  title={Generating realistic artificial Human genomes using adversarial autoencoders},
  author={Burnard, Callum and Mancheron, Alban and Ritchie, William J},
  journal={bioRxiv},
  pages={2023--12},
  year={2023},
  publisher={Cold Spring Harbor Laboratory}
}

@article{ahronoviz2024genome,
  title={Genome-AC-GAN: Enhancing Synthetic Genotype Generation through Auxiliary Classification},
  author={Ahronoviz, Shaked and Gronau, Ilan},
  journal={bioRxiv},
  pages={2024--02},
  year={2024},
  publisher={Cold Spring Harbor Laboratory}
}

@article{1000genome,
  title={A global reference for human genetic variation},
  author={1000 Genomes Project Consortium and others},
  journal={Nature},
  volume={526},
  number={7571},
  pages={68},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{szatkownik2024towards,
  title={Towards creating longer genetic sequences with GANs: Generation in principal component space},
  author={Szatkownik, Antoine and Furtlehner, Cyril and Charpiat, Guillaume and Yelmen, Burak and Jay, Flora},
  booktitle={Machine Learning in Computational Biology},
  pages={110--122},
  year={2024},
  organization={PMLR}
}

@article{yelmen2023deep,
  title={Deep convolutional and conditional neural networks for large-scale genomic data generation},
  author={Yelmen, Burak and Decelle, Aur{\'e}lien and Boulos, Leila Lea and Szatkownik, Antoine and Furtlehner, Cyril and Charpiat, Guillaume and Jay, Flora},
  journal={PLoS Computational Biology},
  volume={19},
  number={10},
  pages={e1011584},
  year={2023},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{stablediffusion,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@article{hapnest,
    author = {Wharrie, Sophie and Yang, Zhiyu and Raj, Vishnu and Monti, Remo and Gupta, Rahul and Wang, Ying and Martin, Alicia and O’Connor, Luke J and Kaski, Samuel and Marttinen, Pekka and Palamara, Pier Francesco and Lippert, Christoph and Ganna, Andrea},
    title = "{HAPNEST: efficient, large-scale generation and evaluation of synthetic datasets for genotypes and phenotypes}",
    journal = {Bioinformatics},
    volume = {39},
    number = {9},
    pages = {btad535},
    year = {2023},
    month = {08},
    abstract = "{Existing methods for simulating synthetic genotype and phenotype datasets have limited scalability, constraining their usability for large-scale analyses. Moreover, a systematic approach for evaluating synthetic data quality and a benchmark synthetic dataset for developing and evaluating methods for polygenic risk scores are lacking.We present HAPNEST, a novel approach for efficiently generating diverse individual-level genotypic and phenotypic data. In comparison to alternative methods, HAPNEST shows faster computational speed and a lower degree of relatedness with reference panels, while generating datasets that preserve key statistical properties of real data. These desirable synthetic data properties enabled us to generate 6.8 million common variants and nine phenotypes with varying degrees of heritability and polygenicity across 1 million individuals. We demonstrate how HAPNEST can facilitate biobank-scale analyses through the comparison of seven methods to generate polygenic risk scoring across multiple ancestry groups and different genetic architectures.A synthetic dataset of 1 008 000 individuals and nine traits for 6.8 million common variants is available at https://www.ebi.ac.uk/biostudies/studies/S-BSST936. The HAPNEST software for generating synthetic datasets is available as Docker/Singularity containers and open source Julia and C code at https://github.com/intervene-EU-H2020/synthetic\_data.}",
    issn = {1367-4811},
    doi = {10.1093/bioinformatics/btad535},
    url = {https://doi.org/10.1093/bioinformatics/btad535},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/39/9/btad535/51501652/btad535.pdf},
}




@inproceedings{bert,
  author       = {Jacob Devlin and
                  Ming{-}Wei Chang and
                  Kenton Lee and
                  Kristina Toutanova},
  editor       = {Jill Burstein and
                  Christy Doran and
                  Thamar Solorio},
  title        = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
                  Understanding},
  booktitle    = {Proceedings of the 2019 Conference of the North American Chapter of
                  the Association for Computational Linguistics: Human Language Technologies,
                  {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
                  and Short Papers)},
  pages        = {4171--4186},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/n19-1423},
  doi          = {10.18653/V1/N19-1423},
  timestamp    = {Mon, 26 Sep 2022 12:21:55 +0200},
  biburl       = {https://dblp.org/rec/conf/naacl/DevlinCLT19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@article{Geleta2023.09.27.558320,
	author = {Geleta, Margarita and Montserrat, Daniel Mas and Giro-i-Nieto, Xavier and Ioannidis, Alexander G.},
	title = {Deep Variational Autoencoders for Population Genetics},
	elocation-id = {2023.09.27.558320},
	year = {2023},
	doi = {10.1101/2023.09.27.558320},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Motivation Modern biobanks provide numerous high-resolution genomic sequences of diverse populations. These datasets enable a better understanding of genotype-phenotype interactions with genome-wide association studies (GWAS) and power a new personalized precision medicine with polygenic risk scores (PRS). In order to account for diverse and admixed populations, new algorithmic tools are needed in order to properly capture the genetic composition of populations. Here we explore deep learning techniques, namely variational autoencoders (VAEs), to process genomic data from a population perspective. We hope this work will encourage the adoption of deep neural networks in the population genetics community.Results In this paper, we show the power of VAEs for a variety of tasks relating to the interpretation, classification, simulation, and compression of genomic data with several worldwide whole genome datasets from both humans and canids and evaluate the performance of the proposed applications with and without ancestry conditioning. The unsupervised setting of autoencoders allows for the detection and learning of granular population structure and inferring of informative latent factors. The learned latent spaces of VAEs are able to capture and represent differentiated Gaussian-like clusters of samples with similar genetic composition on a fine-scale from single nucleotide polymorphisms (SNPs), enabling applications in dimensionality reduction, data simulation, and imputation. These individual genotype sequences can then be decomposed into latent representations and reconstruction errors (residuals) which provide a sparse representation useful for lossless compression. We show that different population groups have differentiated compression ratios and classification accuracies. Additionally, we analyze the entropy of the SNP data, its effect on compression across populations, its relation to historical migrations, and we show how to introduce autoencoders into existing compression pipelines.Competing Interest StatementA.G.I. holds shares in Galatea Bio. The remaining authors declare no competing interests.ANNartificial neural network;VAEvariational autoencoder;GWASgenome-wide association study;SNPsingle nucleotide polymorphism;MLPmultilayer perceptron;LAIlocal ancestry inference;PPMprediction by partial matching;GRUgated recurrent unit;LSTMlong short-term memory;LDlinkage disequilibrium;GANgenerative adversarial network;RBMrestricted boltzmann machine;ReLUrectified linear unit;GELUgaussian error linear unit;MAFminor allele frequency;BCEbinary cross-entropy;KLKullback-Leibler;MAPmaximum a posteriori;PCAprincipal component analysis;DBIDavies-Bouldin index;SCsilhouette coefficient;AFRAfrican;EUREuropean;AMRNative American;WASWest Asian;SASSouth Asian;OCEOceanian;RLErun-length encoding;MCARmissing completely at random;MNARmissing not at random;VQ-VAEvector quantized variational autoencoder;},
	URL = {https://www.biorxiv.org/content/early/2023/09/28/2023.09.27.558320},
	eprint = {https://www.biorxiv.org/content/early/2023/09/28/2023.09.27.558320.full.pdf},
	journal = {bioRxiv}
}

@article{classifierfree,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}

@article{project2018project,
  title={Project MinE: study design and pilot analyses of a large-scale whole-genome sequencing study in amyotrophic lateral sclerosis},
  journal={European Journal of Human Genetics},
  volume={26},
  number={10},
  pages={1537--1546},
  year={2018},
  publisher={Springer International Publishing Cham}
}


@InProceedings{capsulenet,
author={Luo, Xiao
and Kang, Xiongbin
and Schönhuth, Alexander},
title="Predicting the prevalence of complex genetic diseases from individual genotype profiles using capsule networks",
booktitle="Nature Machine Intelligence",
year="2023",
publisher="Nature Publishing",
isbn="978-3-319-24574-4"
}

@article{UMAP, doi = {10.21105/joss.00861}, url = {https://doi.org/10.21105/joss.00861}, year = {2018}, publisher = {The Open Journal}, volume = {3}, number = {29}, pages = {861}, author = {Leland McInnes and John Healy and Nathaniel Saul and Lukas Großberger}, title = {UMAP: Uniform Manifold Approximation and Projection}, journal = {Journal of Open Source Software} }

@article{tsne,
  author  = {Laurens van der Maaten and Geoffrey Hinton},
  title   = {Visualizing Data using t-SNE},
  journal = {Journal of Machine Learning Research},
  year    = {2008},
  volume  = {9},
  number  = {86},
  pages   = {2579--2605},
  url     = {http://jmlr.org/papers/v9/vandermaaten08a.html}
}

@article{somepalli2023understanding,
  title={Understanding and mitigating copying in diffusion models},
  author={Somepalli, Gowthami and Singla, Vasu and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={47783--47803},
  year={2023}
}

@article{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={8780--8794},
  year={2021}
}

@article{sarkar2024designing,
  title={Designing DNA With Tunable Regulatory Activity Using Discrete Diffusion},
  author={Sarkar, Anirban and Tang, Ziqi and Zhao, Chris and Koo, Peter},
  journal={bioRxiv},
  pages={2024--05},
  year={2024},
  publisher={Cold Spring Harbor Laboratory}
}

@inproceedings{avdeyev2023dirichlet,
  title={Dirichlet diffusion score model for biological sequence generation},
  author={Avdeyev, Pavel and Shi, Chenlai and Tan, Yuhao and Dudnyk, Kseniia and Zhou, Jian},
  booktitle={International Conference on Machine Learning},
  pages={1276--1301},
  year={2023},
  organization={PMLR}
}

@inproceedings{senan2024dna,
  title={DNA-Diffusion: Leveraging Generative Models for Controlling Chromatin Accessibility and Gene Expression via Synthetic Regulatory Elements},
  author={Senan, Simon and Reddy, Aniketh Janardhan and Nussbaum, Zach and Wenteler, Aaron and Bejan, Matei and Love, Michael I and Meuleman, Wouter and Pinello, Luca},
  booktitle={ICLR 2024 Workshop on Machine Learning for Genomics Explorations},
  year={2024}
}


@article{li2024discdiff,
  title={DiscDiff: Latent Diffusion Model for DNA Sequence Generation},
  author={Li, Zehui and Ni, Yuhao and Beardall, William AV and Xia, Guoxuan and Das, Akashaditya and Stan, Guy-Bart and Zhao, Yiren},
  journal={arXiv preprint arXiv:2402.06079},
  year={2024}
}

@article{schiff2024caduceus,
  title={Caduceus: Bi-directional equivariant long-range dna sequence modeling},
  author={Schiff, Yair and Kao, Chia-Hsiang and Gokaslan, Aaron and Dao, Tri and Gu, Albert and Kuleshov, Volodymyr},
  journal={arXiv preprint arXiv:2403.03234},
  year={2024}
}
